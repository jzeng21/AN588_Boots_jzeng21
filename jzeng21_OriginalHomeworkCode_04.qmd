---
title: "jzeng21_OriginalHomeworkCode_04"
format: html
editor: visual
---

## Question 1

```{r}
data <- read.csv("C:\\Users\\jzeng21\\Desktop\\AN588\\AN588_Boots_jzeng21\\KamilarAndCooperData.csv")

data$logHR <- log(data$HomeRange_km2)
data$logBM <- log(data$Body_mass_female_mean)

model <- lm(logHR ~ logBM, data = data)
summary(model)$coefficients
```

Intercept : -9.441231

Slope (logBM) : 1.036432

Equation: log(HomeRange~km^2^~)= -9.441231 + 1.036432 x log(BodyMass~female~)

## Question 2

```{r}
set.seed(123)# reproducitbility
nboot <- 1000 #setting how many boots

#generating sampling distribution for each B coefficient
boot_coefficients <- replicate(nboot, {
  sample_data <- data[sample(nrow(data), replace = TRUE),]
  coef(lm(logHR ~ logBM, data = sample_data))
})


boot_coefficients <- t(boot_coefficients) #transposing the data set 
colnames(boot_coefficients) <- c("Intercept", "logBM")

#compute standard errors and confidence intervals
boot_results <- apply(boot_coefficients, 2, function(x){
  se <- sd(x)
  ci <- quantile(x, probs = c(0.025, 0.0975))
  c(SE = se, LowerCI = ci[1], UpperCI = ci[2])
})

boot_results



```

```{r}
confint(model)
summary(model)$coefficients[, "Std. Error"]
```

Here I made a table to compare the SE from lm and boot we can see that the bootstrap SE is slightly smaller in intercepty and for the logBM as well. This shows that the method used for lm and bootstrap is consistent in results with minor differences.

| Coefficient | SE from `lm()` | SE from Bootstrapping | Comparison |
|-------------|----------------|-----------------------|------------|

|           |        |        |                                  |
|-----------|--------|--------|----------------------------------|
| Intercept | 0.6729 | 0.6030 | Bootstrap SE is slightly smaller |

|       |        |        |                                  |
|-------|--------|--------|----------------------------------|
| logBM | 0.0849 | 0.0785 | Bootstrap SE is slightly smaller |

Here I made a table for the confidence intervals as well, here the table shows that the bootstrap confidence intervals are narrower which = less variability.

| Coefficient | 95% CI from `lm()` | 95% CI from Bootstrapping | Comparison |
|----|----|----|----|
| Intercept | \[-10.6796, -8.2029\] *(calc'd)* | \[-10.6796, -10.2130\] | Bootstrap CI is narrower & lower |
| logBM | \[0.8895, 1.1833\] *(calc'd)* | \[0.8895, 0.9332\] | Bootstrap CI is much narrower |

Overall results show robustness.

## Extra Credit 1

```{r}
boot_lm <- function(d, m, conf.level = 0.95, n = 1000) {
  mod <- lm(as.formula(m), data = d)
  full_coefs <- coef(mod)
  full_se <- summary(mod)$coefficients[, "Std. Error"]
  full_ci <- confint(mod, level = conf.level)
  
  boot_out <- replicate(n, {
    samp <- d[sample(nrow(d), replace = TRUE), ]
    coef(lm(as.formula(m), data = samp))
  })
  
  boot_out <- t(boot_out)
  se_boot <- apply(boot_out, 2, sd)
  ci_boot <- apply(boot_out, 2, function(x) quantile(x, probs = c((1 - conf.level) / 2, 1 - (1 - conf.level) / 2)))
  mean_boot <- apply(boot_out, 2, mean)
  
  df <- data.frame(
    Coef = names(full_coefs),
    Original_Estimate = full_coefs,
    Original_SE = full_se,
    Original_LowerCI = full_ci[, 1],
    Original_UpperCI = full_ci[, 2],
    Boot_Mean = mean_boot,
    Boot_SE = se_boot,
    Boot_LowerCI = ci_boot[1, ],
    Boot_UpperCI = ci_boot[2, ]
  )
  
  return(df)
}

boot_lm(data, "logHR ~ logBM")

```

## Extra Credit 2

```{r}
library(ggplot2)
library(reshape2)

boot_convergence <- function(d, m) {
  mod <- lm(as.formula(m), data = d)
  betas <- coef(mod)
  boot_seq <- seq(10, 200, by = 10)
  out_list <- list()

  for (n in boot_seq) {
    boots <- replicate(n, {
      samp <- d[sample(nrow(d), replace = TRUE), ]
      coef(lm(as.formula(m), data = samp))
    })
    boots <- t(boots)
    mean_boot <- apply(boots, 2, mean)
    ci_boot <- apply(boots, 2, function(x) quantile(x, probs = c(0.025, 0.975)))

    temp <- data.frame(
      NumBoots = n,
      Coef = names(mean_boot),
      Mean = mean_boot,
      Lower = ci_boot[1, ],
      Upper = ci_boot[2, ],
      Original = betas
    )
    out_list[[length(out_list) + 1]] <- temp
  }

  final_df <- do.call(rbind, out_list)
  return(final_df)
}

plot_df <- boot_convergence(data, "logHR ~ logBM")

ggplot(plot_df, aes(x = NumBoots, y = Mean, color = Coef)) +
  geom_line() +
  geom_ribbon(aes(ymin = Lower, ymax = Upper, fill = Coef), alpha = 0.2, linetype = 0) +
  geom_hline(aes(yintercept = Original, color = Coef), linetype = "dashed") +
  facet_wrap(~ Coef, scales = "free_y") +
  labs(title = "Bootstrap CI Convergence", y = "Coefficient Value", x = "Number of Bootstraps") +
  theme_minimal()
```
